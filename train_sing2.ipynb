{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2faca300",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import logging\n",
    "import pdb\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import wandb\n",
    "\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from tqdm import tqdm\n",
    "\n",
    "from utils.data_loading import BasicDataset, CarvanaDataset\n",
    "from utils.dice_score import dice_loss\n",
    "from evaluate import evaluate\n",
    "from unet import UNet\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6f07651",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_low = Path('./data/data_nature/low/')\n",
    "dir_high = Path('./data/data_nature/high/')\n",
    "final_model_path = Path('./')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "05a1dbf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_net(net,\n",
    "              device,\n",
    "              epochs: int = 5,\n",
    "              batch_size: int = 1,\n",
    "              learning_rate: float = 1e-5,\n",
    "              val_percent: float = 0.2,\n",
    "              save_checkpoint: bool = True,\n",
    "              low_scale: float = 1.0,\n",
    "              amp: bool = False):\n",
    "    # 1. Create dataset\n",
    "    try:\n",
    "        dataset = CarvanaDataset(dir_low, dir_high, low_scale)\n",
    "    except (AssertionError, RuntimeError):\n",
    "        dataset = BasicDataset(dir_low, dir_high, low_scale)\n",
    "    # 2. Split into train / validation partitions\n",
    "    n_val = int(len(dataset) * val_percent)\n",
    "    n_train = len(dataset) - n_val\n",
    "    train_set, val_set = random_split(dataset, [n_train, n_val], generator=torch.Generator().manual_seed(0))\n",
    "\n",
    "    # 3. Create data loaders\n",
    "    loader_args = dict(batch_size=batch_size, num_workers=4, pin_memory=True)\n",
    "    train_loader = DataLoader(train_set, shuffle=True, **loader_args)\n",
    "    val_loader = DataLoader(val_set, shuffle=False, drop_last=True, **loader_args)\n",
    "\n",
    "    # (Initialize logging)\n",
    "    experiment = wandb.init(project='U-Net', resume='allow', anonymous='must')\n",
    "    experiment.config.update(dict(epochs=epochs, batch_size=batch_size, learning_rate=learning_rate,\n",
    "                                  val_percent=val_percent, save_checkpoint=save_checkpoint, low_scale=low_scale,\n",
    "                                  amp=amp))\n",
    "\n",
    "    logging.info(f'''Starting training:\n",
    "        Epochs:          {epochs}\n",
    "        Batch size:      {batch_size}\n",
    "        Learning rate:   {learning_rate}\n",
    "        Training size:   {n_train}\n",
    "        Validation size: {n_val}\n",
    "        Checkpoints:     {save_checkpoint}\n",
    "        Device:          {device.type}\n",
    "        Images scaling:  {low_scale}\n",
    "        Mixed Precision: {amp}\n",
    "    ''')\n",
    "\n",
    "    # 4. Set up the optimizer, the loss, the learning rate scheduler and the loss scaling for AMP\n",
    "    optimizer = optim.RMSprop(net.parameters(), lr=learning_rate, weight_decay=1e-8, momentum=0.9)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'max', patience=2)  # goal: maximize Dice score\n",
    "    grad_scaler = torch.cuda.amp.GradScaler(enabled=amp)\n",
    "    #criterion = nn.CrossEntropyLoss()\n",
    "    criterion = nn.L1Loss()\n",
    "    global_step = 0\n",
    "    \n",
    "    g_loss = np.zeros(epochs)\n",
    "    p_loss = np.zeros(epochs)\n",
    "    v_loss = np.zeros(epochs)\n",
    "    # 5. Begin training\n",
    "    div = epochs/10\n",
    "    for epoch in range(1, epochs+1):\n",
    "        net.train()\n",
    "        epoch_loss = 0\n",
    "        with tqdm(total=n_train, desc=f'Epoch {epoch}/{epochs}', unit='img') as pbar:\n",
    "            for batch in train_loader:\n",
    "                lows = batch['low']\n",
    "                true_highs = batch['high']\n",
    "                idx = batch['idx']\n",
    "                \n",
    "                assert lows.shape[1] == net.n_channels, \\\n",
    "                    f'Network has been defined with {net.n_channels} input channels, ' \\\n",
    "                    f'but loaded images have {images.shape[1]} channels. Please check that ' \\\n",
    "                    'the images are loaded correctly.'\n",
    "\n",
    "                lows = lows.to(device=device, dtype=torch.float32)\n",
    "                true_highs = true_highs.to(device=device, dtype=torch.long)\n",
    "\n",
    "                with torch.cuda.amp.autocast(enabled=amp):\n",
    "                    highs_pred = net(lows)\n",
    "                    pred = highs_pred.detach().cpu().numpy()[0,0,:,:]\n",
    "                    idx = idx[0].split('/')[3].split('.')[0]\n",
    "                    if epoch % 10 == 0:\n",
    "                        np.save('./data/data_nature/result/%s.npy'%idx, pred)\n",
    "                    loss = criterion(highs_pred, true_highs)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                grad_scaler.scale(loss).backward()\n",
    "                grad_scaler.step(optimizer)\n",
    "                grad_scaler.update()\n",
    "\n",
    "                pbar.update(lows.shape[0])\n",
    "                global_step += 1\n",
    "                epoch_loss += loss.item()\n",
    "                experiment.log({\n",
    "                    'train loss': loss.item(),\n",
    "                    'step': global_step,\n",
    "                    'epoch': epoch\n",
    "                })\n",
    "                pbar.set_postfix(**{'loss (batch)': loss.item()})\n",
    "                \n",
    "# validation part          \n",
    "        with tqdm(total=n_val, desc=f'Test {epoch}/{epochs}', unit='img') as pbar:\n",
    "            for batch in val_loader:\n",
    "                lows = batch['low']\n",
    "                true_highs = batch['high']\n",
    "                idx = batch['idx']\n",
    "            \n",
    "                assert lows.shape[1] == net.n_channels, \\\n",
    "                    f'Network has been defined with {net.n_channels} input channels, ' \\\n",
    "                    f'but loaded images have {images.shape[1]} channels. Please check that ' \\\n",
    "                    'the images are loaded correctly.'\n",
    "\n",
    "                lows = lows.to(device=device, dtype=torch.float32)\n",
    "                true_highs = true_highs.to(device=device, dtype=torch.long)\n",
    "\n",
    "                with torch.cuda.amp.autocast(enabled=amp):\n",
    "                    highs_pred = net(lows)\n",
    "                    pred = highs_pred.detach().cpu().numpy()[0,0,:,:]\n",
    "                    val_loss = criterion(highs_pred, true_highs)\n",
    "\n",
    "                pbar.update(lows.shape[0])\n",
    "                \n",
    "                experiment.log({\n",
    "                    'validation loss': loss.item(),\n",
    "                    'step': global_step,\n",
    "                    'epoch': epoch\n",
    "                })\n",
    "                pbar.set_postfix(**{'loss (batch)': val_loss.item()})\n",
    "\n",
    "        experiment.log({\n",
    "            'epoch loss': epoch_loss\n",
    "        })\n",
    "        g_loss[epoch-1] = epoch_loss\n",
    "        p_loss[epoch-1] = loss.item()        \n",
    "        v_loss[epoch-1] = val_loss.item()\n",
    "        np.save('./loss/p_loss_nature.npy',p_loss)\n",
    "        np.save('./loss/v_loss_nature.npy',v_loss)\n",
    "        if epoch == epochs:\n",
    "            torch.save(net.state_dict(), str(final_model_path / 'MODEL_nature.pth'))\n",
    "            logging.info('Final model is saved!')\n",
    "            plt.figure(figsize=(20,10))\n",
    "            plt.plot(p_loss)     \n",
    "            plt.figure(figsize=(20,10))\n",
    "            plt.plot(v_loss)\n",
    "        elif save_checkpoint:\n",
    "            if epoch % 10 == 0:\n",
    "                torch.save(net.state_dict(), str(final_model_path / 'MODEL_nature.pth'))\n",
    "                logging.info('P model is saved!')\n",
    "#                 Path(dir_checkpoint).mkdir(parents=True, exist_ok=True)\n",
    "#                 torch.save(net.state_dict(), str(dir_checkpoint / 'checkpoint_epoch{}.pth'.format(epoch)))\n",
    "#                 logging.info(f'Checkpoint {epoch} saved!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "79379cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "looping_epochs = 300\n",
    "\n",
    "def get_args():\n",
    "    parser = argparse.ArgumentParser(description='Train the UNet on images and target masks')\n",
    "    parser.add_argument('--epochs', '-e', metavar='E', type=int, default=looping_epochs, help='Number of epochs')\n",
    "    parser.add_argument('--batch-size', '-b', dest='batch_size', metavar='B', type=int, default=1, help='Batch size')\n",
    "    parser.add_argument('--learning-rate', '-l', metavar='LR', type=float, default=1e-5,\n",
    "                        help='Learning rate', dest='lr')\n",
    "    parser.add_argument('--load', '-f', type=str, default=False, help='Load model from a .pth file')\n",
    "    parser.add_argument('--scale', '-s', type=float, default=1.0, help='Downscaling factor of the images')\n",
    "    parser.add_argument('--validation', '-v', dest='val', type=float, default=1.0,\n",
    "                        help='Percent of the data that is used as validation (0-100)')\n",
    "    parser.add_argument('--amp', action='store_true', default=False, help='Use mixed precision')\n",
    "    parser.add_argument('--bilinear', action='store_true', default=False, help='Use bilinear upsampling')\n",
    "    parser.add_argument('--classes', '-c', type=int, default=1, help='Number of classes')\n",
    "    return parser.parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec0cdd70",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    args = get_args()\n",
    "\n",
    "    logging.basicConfig(level=logging.INFO, format='%(levelname)s: %(message)s')\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    logging.info(f'Using device {device}')\n",
    "    net = UNet(n_channels=1, n_classes=args.classes, bilinear=args.bilinear) #args.classes, bilinear=args.bilinear)\n",
    "\n",
    "    logging.info(f'Network:\\n'\n",
    "                  f'\\t{net.n_channels} input channels\\n'\n",
    "                  f'\\t{net.n_classes} output channels (classes)\\n'\n",
    "                  f'\\t{\"Bilinear\" if net.bilinear else \"Transposed conv\"} upscaling')\n",
    "    \n",
    "    args.load = './MODEL_nature.pth'\n",
    "#     args.load = ''\n",
    "    if args.load:\n",
    "        net.load_state_dict(torch.load(args.load, map_location=device))\n",
    "        logging.info(f'Model loaded from {args.load}')\n",
    "    net.to(device=device)\n",
    "    try:\n",
    "        train_net(net=net,\n",
    "                  epochs=args.epochs,\n",
    "                  batch_size=args.batch_size,\n",
    "                  learning_rate=args.lr,\n",
    "                  device=device,\n",
    "                  low_scale=args.scale,\n",
    "                  val_percent=args.val / 100,\n",
    "                  amp=args.amp)\n",
    "    except KeyboardInterrupt:\n",
    "        torch.save(net.state_dict(), 'INTERRUPTED.pth')\n",
    "        logging.info('Saved interrupt')\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18537754",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:opence-v1.0.0]",
   "language": "python",
   "name": "conda-env-opence-v1.0.0-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
